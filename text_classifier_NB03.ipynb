{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_classifier_NB03.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxQtg8Q5vU_O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "583921c7-dde4-45b2-af11-fa8904a7fb33"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('movie_reviews')\r\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bF3EPnwvOEK"
      },
      "source": [
        "#the following two lines is to load data\r\n",
        "#it pops up a separate window, Select corpora, then download Movie Reviews\r\n",
        "#import nltk\r\n",
        "#nltk.download()\r\n",
        "\r\n",
        "print(\"Naive Bayes Text classification\")\r\n",
        "\r\n",
        "print('step 1: ')\r\n",
        "from nltk.corpus import movie_reviews as mr\r\n",
        "#print(mr.readme())\r\n",
        "# divide the movie_reviews into 2 categories: positive and negative\r\n",
        "positive = mr.fileids('pos')\r\n",
        "negative = mr.fileids('neg')\r\n",
        "# form a new movie_reviews as a dictionary by positive and negative\r\n",
        "new_mr = dict(pos = positive, neg = negative)\r\n",
        "# the length of positive and negative lists are both 1000\r\n",
        "posLen = len(new_mr['pos'])\r\n",
        "negLen = len(new_mr['neg'])\r\n",
        "print('movie reviews are loaded with ')\r\n",
        "print('%s positive reviews ' % posLen)\r\n",
        "print('%s negative reviews ' % negLen)\r\n",
        "print()\r\n",
        "\r\n",
        "\r\n",
        "print('step 2: ')\r\n",
        "from nltk.corpus import stopwords\r\n",
        "sw = stopwords.words('english');\r\n",
        "# here in the stopwords list 'sw'\r\n",
        "# it should remove some words from the list\r\n",
        "# such as: 'no','nor','not','too', and\r\n",
        "# \"don't\",\"aren't\", \"couldn't\", 'didn', \"didn't\", \r\n",
        "# \"doesn't\", \"hadn't\", \"hasn't\", \"haven't\", \"isn't\", \"mightn't\",\r\n",
        "#  \"mustn't\", \"needn't\", \"shan't\", \"shouldn't\", \"wasn't\", \"weren't\",\r\n",
        "#  \"won't\", \"wouldn't\"\r\n",
        "sw.remove('no')\r\n",
        "sw.remove('nor')\r\n",
        "sw.remove('not')\r\n",
        "sw.remove('too')\r\n",
        "sw1 = []\r\n",
        "for v in sw:\r\n",
        "    if not v.endswith(\"n't\"):\r\n",
        "        sw1.append(v)\r\n",
        "    #else:\r\n",
        "        #print(v)\r\n",
        "sw1.remove('ain')\r\n",
        "sw1.remove('aren')\r\n",
        "sw1.remove('couldn')\r\n",
        "sw1.remove('didn')\r\n",
        "sw1.remove('doesn')\r\n",
        "sw1.remove('hadn')\r\n",
        "sw1.remove('haven')\r\n",
        "sw1.remove('isn')\r\n",
        "sw1.remove('mightn')\r\n",
        "sw1.remove('hasn')\r\n",
        "sw1.remove('mustn')\r\n",
        "sw1.remove('needn')\r\n",
        "sw1.remove('shan')\r\n",
        "sw1.remove('wasn')\r\n",
        "sw1.remove('weren')\r\n",
        "sw1.remove('wouldn')\r\n",
        "sw = sw1\r\n",
        "#print(len(sw))\r\n",
        "print('there are %s stopwords loaded' % len(sw))\r\n",
        "\r\n",
        "# input a word, \r\n",
        "# determine whether it is a stopword or not\r\n",
        "# remove all punctuations from the word\r\n",
        "# to lower case\r\n",
        "def pre_process(word, sw):\r\n",
        "  # remove punctuations except apostrophe\r\n",
        "  w = \"\"\r\n",
        "  hasAlphabet = False\r\n",
        "  for i in word:\r\n",
        "    if i >= 'a' and i <= 'z':\r\n",
        "      w = w + i\r\n",
        "      hasAlphabet = True\r\n",
        "    elif i >= 'A' and i <= 'Z':\r\n",
        "      w = w + i\r\n",
        "      hasAlphabet = True\r\n",
        "    elif i == '\\'': # apostrophe\r\n",
        "      w = w + i\r\n",
        "  #print(w)\r\n",
        "  # check whether it is stopword\r\n",
        "  if hasAlphabet and w not in sw:\r\n",
        "    return w.lower()\r\n",
        "  return ''\r\n",
        "\r\n",
        "\r\n",
        "# selection the 3000 most important words.\r\n",
        "# find the 3000 most important words by frequency\r\n",
        "# top, is how many words in the list to be returned\r\n",
        "# in this program, top is 2048\r\n",
        "def importantWords(corpus, file, top, sw):\r\n",
        "  iw = []\r\n",
        "  words_dic = {}\r\n",
        "  pLen = len(file['pos'])\r\n",
        "  i = 0\r\n",
        "  while i < pLen:\r\n",
        "    movie_review = corpus.words(file['pos'][i])\r\n",
        "    for w in movie_review:\r\n",
        "      w = pre_process(w, sw)\r\n",
        "      if w not in words_dic:\r\n",
        "        words_dic[w] = 1\r\n",
        "      else:\r\n",
        "        words_dic[w] = words_dic[w] + 1\r\n",
        "    i = i + 1\r\n",
        "  nLen = len(file['neg'])\r\n",
        "  i = 0\r\n",
        "  while i < nLen:\r\n",
        "    movie_review = corpus.words(file['neg'][i])\r\n",
        "    for w in movie_review:\r\n",
        "      w = pre_process(w, sw)\r\n",
        "      if len(w) > 0:\r\n",
        "        if w not in words_dic:\r\n",
        "          words_dic[w] = 1\r\n",
        "        else:\r\n",
        "          words_dic[w] = words_dic[w] + 1\r\n",
        "      else:\r\n",
        "        continue\r\n",
        "    i = i + 1\r\n",
        "  words_dic.pop('') # remove space\r\n",
        "  sorted_words_dic = sorted(words_dic.items(), key = lambda kv:(kv[1], kv[0]), reverse=True)\r\n",
        "  # add the top words to the list to be returned\r\n",
        "  i = 0\r\n",
        "  while i < top:\r\n",
        "    iw.append(sorted_words_dic[i][0])\r\n",
        "    #print(sorted_words_dic[i])\r\n",
        "    i = i + 1\r\n",
        "  return iw\r\n",
        "\r\n",
        "# this method finally not used\r\n",
        "# focus on the adj. words \r\n",
        "# always end with: \r\n",
        "# and negative words such as: no, nor, not, n't\r\n",
        "def focusWords(word):\r\n",
        "  adj_list = [ 'ant', 'ary', 'ble', 'cal', 'ed', 'ful', 'ic', 'ish', 'ive', 'lar', 'less', 'ous', 'y']\r\n",
        "  for w in adj_list:\r\n",
        "      if word.endswith(w):\r\n",
        "          return True\r\n",
        "  neg_list = ['no', 'nor', 'not', 'too', 'never', 'little']\r\n",
        "  for w in neg_list:\r\n",
        "      if w == word:\r\n",
        "          return True\r\n",
        "  if word.endswith(\"n't\"):\r\n",
        "      return True\r\n",
        "  neg_phrase = ['ain', 'aren', 'couldn', 'didn', 'doesn', 'hadn', 'haven', 'isn', 'mightn', 'hasn', 'mustn', 'needn', 'wasn', 'weren', 'wouldn']\r\n",
        "  for w in neg_phrase:\r\n",
        "      if word.startswith(w):\r\n",
        "          return True\r\n",
        "  return False\r\n",
        "\r\n",
        "\r\n",
        "# iw, the given data is the most-important-word list\r\n",
        "# tmp_dic, the given data that represents all the words of a movie review\r\n",
        "# generate a certain size dict-type data\r\n",
        "# sample: [0:True, 2:False, ..., 2047: True]\r\n",
        "# 0, .. , 2047, is the index corresponding to the words stored in the most-important-word list\r\n",
        "# True, means the index word is also exsiting in tmp_dic, False means not\r\n",
        "def generate_feature(iw, tmp_dic):\r\n",
        "  arrayLen = len(iw)\r\n",
        "  features = {}\r\n",
        "  i = 0\r\n",
        "  while i < arrayLen:\r\n",
        "    w = iw[i]\r\n",
        "    if w in tmp_dic:\r\n",
        "      features[i] = True\r\n",
        "    else:\r\n",
        "      features[i] = False\r\n",
        "    i = i + 1\r\n",
        "  return features\r\n",
        "\r\n",
        "# select almost every word as a feature\r\n",
        "# the input parameter is a list consisting of words\r\n",
        "# and return a dictionary which includes useful words after pre-processing\r\n",
        "def feature_selection(words, sw, iw):\r\n",
        "  wd = {}\r\n",
        "  for word in words:\r\n",
        "    word = pre_process(word, sw)\r\n",
        "    if len(word) > 0:\r\n",
        "      wd[word] = True\r\n",
        "  wd = generate_feature(iw, wd)\r\n",
        "  return wd\r\n",
        "\r\n",
        "# collect several/some/many dict-type positive or negative movie reviews into a list\r\n",
        "# for training or testing\r\n",
        "# the returned list is composed of tuple\r\n",
        "# every tuple is the ict-type positive or negative movie reviews + clf\r\n",
        "# corpus, should be the 'mr'\r\n",
        "# files, should be the 'new_mr'\r\n",
        "# clf, is the classification: pos or neg\r\n",
        "def collect_features(corpus, files, startID, endID, clf, sw, iw):\r\n",
        "  col = []\r\n",
        "  i = startID\r\n",
        "  while i < endID:\r\n",
        "    dic = feature_selection(corpus.words(files[clf][i]), sw, iw)\r\n",
        "    tup = (dic, clf)\r\n",
        "    col.append(tup)\r\n",
        "    i = i + 1\r\n",
        "  return col\r\n",
        "\r\n",
        "# generate a most-important-word list\r\n",
        "# that store the top 2048 words by frequency\r\n",
        "# and store them in a list\r\n",
        "top = 128 * 2 * 2 * 2 * 2 * 2\r\n",
        "iw = importantWords(mr, new_mr, top, sw )\r\n",
        "\r\n",
        "\r\n",
        "# divide the whole set into train and test sets\r\n",
        "train_start_id = 0\r\n",
        "train_end_id = 900\r\n",
        "test_start_id = 900\r\n",
        "test_end_id = 1000\r\n",
        "\r\n",
        "# collect train and test sets by using feature selection method\r\n",
        "pos_train = collect_features(mr, new_mr, train_start_id, train_end_id, 'pos', sw, iw)\r\n",
        "pos_test = collect_features(mr, new_mr, test_start_id, test_end_id, 'pos', sw, iw)\r\n",
        "neg_train = collect_features(mr, new_mr, train_start_id, train_end_id, 'neg', sw, iw)\r\n",
        "neg_test = collect_features(mr, new_mr, test_start_id, test_end_id, 'neg', sw, iw)\r\n",
        "\r\n",
        "# whole sets\r\n",
        "train_set = pos_train + neg_train\r\n",
        "test_set = pos_test + neg_test\r\n",
        "\r\n",
        "# shuffle the order of the train and test sets\r\n",
        "from sklearn.utils import shuffle\r\n",
        "train_set = shuffle( train_set )\r\n",
        "test_set = shuffle( test_set )\r\n",
        "\r\n",
        "print('pre-processing: remove punctuations except apostrophe and to lower case')\r\n",
        "print('feature selection: geenrate the top %s most-important-word list by frequency' %top)\r\n",
        "print('use the most-important-word list to extract features of every movie review, which will be a certain size dict-type data')\r\n",
        "print('divide the movie reviews into training and testing set after above processing')\r\n",
        "print('training set: 90% \\ntesting set: 10%')\r\n",
        "print()\r\n",
        "\r\n",
        "\r\n",
        "print('step 3:')\r\n",
        "# text classification\r\n",
        "# use Naive Bayes Classifier\r\n",
        "from nltk.classify import NaiveBayesClassifier\r\n",
        "print('text classification: Naive Bayes Text classification')\r\n",
        "\r\n",
        "# Train a classifier on our training data.\r\n",
        "classifier = NaiveBayesClassifier.train(train_set)\r\n",
        "print('using NB classifier to train the model on 90% of movie reviews')\r\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABtEJfI83AGL",
        "outputId": "0a3af916-d1d3-4c87-9fe7-f47c8e1574f5"
      },
      "source": [
        "print('step 4:')\r\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\r\n",
        "print('evaluate trained model on 10% of movie reviews')\r\n",
        "\r\n",
        "# pairs, after using the model to test, it will generate every testing case as a tuple\r\n",
        "# such as: ( 'pos', 'pos' ), the first one is predicted one, and the latter one is actual one\r\n",
        "# pos_label, 'pos' or 'neg'\r\n",
        "# printout, True means to print it out and False means not\r\n",
        "def evaluate(pairs, pos_label, printout):\r\n",
        "    predicted, actual = zip(*pairs)\r\n",
        "    precision = precision_score(actual,predicted,pos_label=pos_label)\r\n",
        "    recall = recall_score(actual,predicted,pos_label=pos_label)\r\n",
        "    accuracy = accuracy_score(actual,predicted)\r\n",
        "    f1 = f1_score(actual,predicted,pos_label=pos_label)\r\n",
        "    if printout:\r\n",
        "      print_evaluation(precision, recall, accuracy, f1, pos_label)\r\n",
        "    return (precision, recall, accuracy, f1)\r\n",
        "\r\n",
        "def print_evaluation(precision, recall, accuracy, f1, pos_label):\r\n",
        "    title =  'Evaluation with pos label = %s' % pos_label\r\n",
        "    print(title)\r\n",
        "    print('=' * len(title))\r\n",
        "    print('{0:10s} {1:.2f} %'.format('Precision',precision*100))\r\n",
        "    print('{0:10s} {1:.2f} %'.format('Recall',recall*100))\r\n",
        "    print('{0:10s} {1:.2f} %'.format('Accuracy',accuracy*100))\r\n",
        "    print('{0:10s} {1:.2f} %'.format('F1 score',f1*100))\r\n",
        "\r\n",
        "pairs = [(classifier.classify(predicted), actual) for (predicted, actual) in test_set]\r\n",
        "printout = True\r\n",
        "precision, recall, accuracy, f1 = evaluate(pairs, 'pos', printout)\r\n",
        "print()\r\n",
        "precision, recall, accuracy, f1 = evaluate(pairs, 'neg', printout)\r\n",
        "print()\r\n",
        "\r\n",
        "\r\n",
        "print('step 5:')\r\n",
        "print('testing the exclusive movie reviews with this model')\r\n",
        "# new testing examples excluded from the move_reviews set\r\n",
        "movie_review = \"Joining the Criterion Collection as #1060, Amores perros is given the full-treatment for its upcoming release: a 4K restoration, new audio tracks, newly recorded bonus materials, essays, and more.\"\r\n",
        "prediction = classifier.classify(feature_selection(movie_review.split(), sw, iw))\r\n",
        "print('moview review is: \\t' + movie_review)\r\n",
        "print('prediction: \\t' + prediction)\r\n",
        "movie_review = \"I find it hard to believe that anyone managed to get any kind of entertainment from the film itself, lurid or otherwise.\"\r\n",
        "prediction = classifier.classify(feature_selection(movie_review.split(), sw, iw))\r\n",
        "print('moview review is: \\t' + movie_review)\r\n",
        "print('prediction: \\t' + prediction)\r\n",
        "classifier.show_most_informative_features()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 4:\n",
            "evaluate trained model on 10% of movie reviews\n",
            "Evaluation with pos label = pos\n",
            "===============================\n",
            "Precision  87.36 %\n",
            "Recall     76.00 %\n",
            "Accuracy   82.50 %\n",
            "F1 score   81.28 %\n",
            "\n",
            "Evaluation with pos label = neg\n",
            "===============================\n",
            "Precision  78.76 %\n",
            "Recall     89.00 %\n",
            "Accuracy   82.50 %\n",
            "F1 score   83.57 %\n",
            "\n",
            "step 5:\n",
            "testing the exclusive movie reviews with this model\n",
            "moview review is: \tJoining the Criterion Collection as #1060, Amores perros is given the full-treatment for its upcoming release: a 4K restoration, new audio tracks, newly recorded bonus materials, essays, and more.\n",
            "prediction: \tneg\n",
            "moview review is: \tI find it hard to believe that anyone managed to get any kind of entertainment from the film itself, lurid or otherwise.\n",
            "prediction: \tneg\n",
            "Most Informative Features\n",
            "                    1730 = True              pos : neg    =     15.6 : 1.0\n",
            "                    2976 = True              neg : pos    =     14.2 : 1.0\n",
            "                    2816 = True              neg : pos    =     11.8 : 1.0\n",
            "                    2470 = True              pos : neg    =     10.2 : 1.0\n",
            "                    2700 = True              neg : pos    =      9.7 : 1.0\n",
            "                    4004 = True              neg : pos    =      9.7 : 1.0\n",
            "                    3894 = True              neg : pos    =      9.4 : 1.0\n",
            "                    3950 = True              neg : pos    =      9.0 : 1.0\n",
            "                    1306 = True              pos : neg    =      9.0 : 1.0\n",
            "                    3169 = True              neg : pos    =      9.0 : 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IwNhlbX4Mhe",
        "outputId": "0fea2cad-b045-4e6e-b5bb-16e0f5f80e8d"
      },
      "source": [
        "print(iw[1730])\r\n",
        "print(iw[2976])\r\n",
        "print(iw[2816])\r\n",
        "print(iw[2470])\r\n",
        "print(iw[2700])\r\n",
        "print(iw[4004])\r\n",
        "print(iw[3894])\r\n",
        "print(iw[3950])\r\n",
        "print(iw[1306])\r\n",
        "print(iw[3169])\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "outstanding\n",
            "ludicrous\n",
            "idiotic\n",
            "religion\n",
            "jolie\n",
            "hudson\n",
            "insulting\n",
            "sucks\n",
            "mulan\n",
            "stupidity\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}